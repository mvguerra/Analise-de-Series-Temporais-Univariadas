---
output:
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
```
## ANÁLISE DE SÉRIES TEMPORAIS UNIVARIADAS\
Trabalho para obtenção de nota no âmbito da disciplina obrigatória de “Estatística Econômica Aplicada” do curso de Mestrado Profissional em Economia – Área de Concentração em Economia – do Programa de Pós-Graduação Profissional em Economia (PPECO) da Faculdade de Ciências Econômicas (FCE) da Universidade Federal do Rio Grande do Sul (UFRGS)\

Aluno: Marcus Vinicius Rossetti Guerra\

Professor: Fernando Augusto Boeira Sabino da Silva\

Junho/2022\
\________________________________________________________________

```{r message = FALSE, warning = FALSE, echo=FALSE, results='hide'}
rm(list=ls())
graphics.off()
library(urca)
library(forecast)
library(astsa)
library(tseries)
library(TSstudio)
library(randomForest)
```
## 1) Série Original\

### a) Arquivo com a série original
df <- "C:/Users/mvrgu/OneDrive/Documentos/Scanned Documents/Mestrado/Estatística Econômica Aplicada/data_MarcusGuerra.csv"\

```{r message = FALSE, warning = FALSE, echo=FALSE, results='hide'}
df <- read.csv("C:/Users/mvrgu/OneDrive/Documentos/Scanned Documents/Mestrado/Estatística Econômica Aplicada/data_MarcusGuerra.csv", header = T,sep = ",", dec = ".")
```
### b) Gráfico da Série Original

```{r, echo=FALSE, results='hide'}
plot(df[,1], df[,2], type = "l", col = "black", lty=1, main="Série Original", xlab="Observações", ylab="Valores", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```

### c) Correlogramas da Série Original

```{r, echo=FALSE, results='hide'}
acf2(df[,2], max.lag=60, main="Correlogramas da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```
ANÁLISE: A ACF da Série Original sugere uma série não estacionária com sazonalidade de 12 períodos.\

### d) Decomposição da Série Original
df1 <- ts(df, frequency=12)

```{r, echo=FALSE, results='hide'}
df1 <- ts(df, frequency=12)
dfcomponents1 <- stl(df1[,2], t.window=13, s.window="periodic", robust=TRUE)
plot(dfcomponents1, main="Decomposição da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```
ANÁLISE: A decomposição da Série Original (com frequência de 12 períodos) sugere presença de tendência.\

DECISÃO: Tirar a Primeira Diferença da Série Original.\

## 2) Primeira Diferença da Série Original\

```{r message = FALSE, warning = FALSE, echo=FALSE, results='hide'}
df.first_diff <- diff(df[,2])
```
### a) Gráfico da Primeira Diferença da Série Original

```{r, echo=FALSE, results='hide'}
plot(df.first_diff, type = "l", col = "black", lty=1, main="Primeira Diferença da Série Original", xlab="Observações", ylab="Valores", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```

### b) Correlogramas da Primeira Diferença da Série Original

```{r, echo=FALSE, results='hide'}
acf2(df.first_diff, max.lag=60, main="Correlogramas da Primeira Diferença da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```
ANÁLISE: A ACF da Primeira Diferença da Série Original não alterou muito a situação. Continua sugerindo uma série não estacionária com sazonalidade de 12 períodos.\

### c) Decomposição da Primeira Diferença da Série Original
df1.first_diff <- diff(df1[,2])

```{r, echo=FALSE, results='hide'}
df1.first_diff <- diff(df1[,2])
dfcomponents2 <- stl(df1.first_diff, t.window=13, s.window="periodic", robust=TRUE)
plot(dfcomponents2, main="Decomposição da Primeira Diferença da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```
ANÁLISE: A decomposição da Primeira Diferença da Série Original (com frequência de 12 períodos) não alterou muito a situação. Continua sugerindo a presença de tendência.\

DECISÃO: Descartar a Primeira Diferença da Série Original. Tirar a Primeira Diferença Sazonal de Ordem 12 da Série Original.\

## 3) Primeira Diferença Sazonal de Ordem 12 da Série Original\

```{r message = FALSE, warning = FALSE, echo=FALSE, results='hide'}
df.first_sdiff12 <- diff(df[,2],12)
```
### a) Gráfico da Primeira Diferença Sazonal de Ordem 12 da Série Original

```{r, echo=FALSE, results='hide'}
plot(df.first_sdiff12, type = "l", col = "black", lty=1, main="Primeira Diferença Sazonal de Ordem 12 da Série Original", xlab="Observações", ylab="Valores", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```

### b) Correlogramas da Primeira Diferença Sazonal de Ordem 12 da Série Original

```{r, echo=FALSE, results='hide'}
acf2(df.first_sdiff12, max.lag=60, main="Correlogramas da Primeira Diferença Sazonal de Ordem 12 da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```
ANÁLISE: A ACF da Primeira Diferença Sazonal de Ordem 12 da Série Original sugere uma série estacionária com sazonalidade de 12 períodos.\

### c) Decomposição da Primeira Diferença Sazonal de Ordem 12 da Série Original
df1.first_sdiff12 <- diff(df1[,2],12)

```{r, echo=FALSE, results='hide'}
df1.first_sdiff12 <- diff(df1[,2],12)
dfcomponents3 <- stl(df1.first_sdiff12, t.window=13, s.window="periodic", robust=TRUE)
plot(dfcomponents3, main="Decomposição da Primeira Diferença Sazonal de Ordem 12 da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```
ANÁLISE: A decomposição da Primeira Diferença Sazonal de Ordem 12 da Série Original (com frequência de 12 períodos) sugere ausença de tendência.\

### d) Teste ADF de raiz unitária - da Primeira Diferença Sazonal de Ordem 12 da Série Original

```{r, echo=FALSE}
test.adf <- ur.df(df1.first_sdiff12, lags = 60, type = "drift", selectlags = "BIC")
summary(test.adf)
```
\
ANÁLISE: O valor da estatistíca -13.7803 é menor que o nível crítico (tau2) -2.87 ao nível de significância de 5%. P-valor é menor que o nível de significância de 5% (0.05).Pode-se concluir pela rejeição da hipótese nula (que a série possui raiz unitária). Portanto, segundo o teste ADF, rejeita-se a hipótese que a série não é estacionária.

### e) Teste KPSS de raiz unitária - da Primeira Diferença Sazonal de Ordem 12 da Série Original

```{r, echo=FALSE}
test.kpss <- ur.kpss(df1.first_sdiff12, type = "mu", use.lag=NULL)
summary(test.kpss)
kpss.test(df1.first_sdiff12)
```
\
ANÁLISE: O valor da estatistíca 0.3776 é menor que o nível crítico 0.463 ao nível de significância de 5%. P-valor é maior que o nível de significância de 5% (0.05). Pode-se concluir pela não rejeição da hipótese nula (que a série não possui raiz unitária). Portanto, segundo o teste KPSS, não se rejeita a hipótese que a série é estacionária.\

DECISÃO: Utilizar a Primeira Diferença Sazonal de Ordem 12 da Série Original para identificar a ordem mais ampla do modelo SARIMA.\

## 4) Identificação da ordem mais ampla do modelo SARIMA\

A FAC (da Primeira Diferença Sazonal de Ordem 12 da Série Original) sugere - conservadoramente - MA(0) para a parte regular e MA(4) para a parte sazonal (q=0 e Q=4).\

A FACP (da Primeira Diferença Sazonal de Ordem 12 da Série Original) sugere - conservadoramente - AR(0) para a parte regular e AR(4) para a parte sazonal (p=0 e P=4).\

Não foi aplicada a primeira diferença (d=0).\

Foi aplicada a primeira diferença sazonal de ordem 12 (D=1).\

DECISÃO: Sugere-se a ordem mais ampla do modelo como SARIMA(0,0,0)(4,1,4)12.\

## 5) Identificação da ordem mais adequada do modelo SARIMA (conforme critério BIC - Bayesian Information Criterion)\

### a) Seleção utilizando a função auto.arima()

```{r message = FALSE, warning = FALSE, echo=FALSE, results='hide'}
(fit13 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(2, 1, 2)))
```

```{r, echo=FALSE}
fit26 <- auto.arima(df1[,2], p=0, d=0, max.q=0, max.P=4, D=1, max.Q=4, stepwise = FALSE, max.order = 8, approximation = FALSE, test = "adf", ic = "bic", trace = TRUE)
summary(fit26)
```
\
ANÁLISE: O menor BIC (4652.76) é o SARIMA(0,0,0)(2,1,2)12.\

### b) Verificação das condições de estacionariedade e invertibilidade

```{r, echo=FALSE, results='hide'}
autoplot(fit13)
```
\
ANÁLISE: No caso do SARIMA(0,0,0)(2,1,2)12, as raízes inversas das equações características dos polinômios (autorregressivo sazonal e de médias móveis sazonal) estão dentro dos círculos unitários. Logo, as condições de estacionariedade e invertibilidade estão satisfeitas.\

DECISÃO: Sugere-se a ordem mais adequada do modelo como SARIMA(0,0,0)(2,1,2)12.\

## 6) Avaliação dos resíduos da ordem (selecionada) mais adequada do modelo SARIMA\

### a) Correlogramas dos resíduos da ordem (selecionada) mais adequada do modelo SARIMA

```{r, echo=FALSE, results='hide'}
acf2(resid(fit13), max.lag=60, cex.main=1, cex.lab=1, font.main=1, font.lab=1)
```
\
ANÁLISE: Quase todas as autocorrelações dos resíduos - da ordem (selecionada) mais adequada do modelo SARIMA - estão dentro dos limites, ou seja, indicando que os resíduos se comportam como um ruído branco.

### b) Teste Ljung-Box de distribuição independente dos resíduos da ordem (selecionada) mais adequada do modelo SARIMA

```{r, echo=FALSE}
checkresiduals(fit13, test="LB")
```
\
ANÁLISE: P-valor é maior que o nível de significância de 5% (0.05). Pode-se concluir pela não rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos). Portanto, segundo o teste Ljung-Box, não se rejeita a hipótese que os resíduos se comportam como um ruído branco.

### c) Teste Jarque-Bera de distribuição normal dos resíduos da ordem (selecionada) mais adequada do modelo SARIMA

```{r, echo=FALSE}
jarque.bera.test(residuals(fit13))
```
\
ANÁLISE: P-valor é maior que o nível de significância de 5% (0.05). Pode-se concluir pela não rejeição da hipótese nula (que os resíduos são normalmente distribuídos). Portanto, segundo o teste Jarque-Bera, não se rejeita a hipótese que os resíduos se comportam como um ruído branco.\

DECISÃO: O exame dos resíduos - da ordem (selecionada) mais adequada do modelo SARIMA - indica que os resíduos se comportam como um ruído branco.

## 7) Seleção do melhor modelo de previsão\

### a) Divisão da Série Original em Série de Treinamento e Série de Teste
df_train <- Série de Treinamento com 476 observações\
df_test <- Série de Teste com 24 observações (frequência = 12 x maior AR/MA da ordem selecionada mais adequada do modelo SARIMA = 2)

```{r message = FALSE, warning = FALSE, echo=FALSE, results='hide'}
df_split <- ts_split(df1[,2], sample.out = 24)
df_train <- df_split$train
df_test <- df_split$test
```

### b) Critérios para avaliação do melhor modelo de previsão
Menor BIC (Bayesian Information Criterion) ou "Critério de Informação Bayesiano".\
Menor RMSE (Root Mean Squared Error) ou "Raiz Quadrada do Erro Médio".\
Menor MAPE (Mean Absolute Percentage Error) ou "Média Percentual Absoluta do Erro".\
Menor Theil's U ou "U de Theil".

### c) Modelo 1 = SARIMA(0,0,0)(2,1,2)12 - ordem (selecionada) mais adequada do modelo SARIMA\

```{r, echo=FALSE}
m1 <- (fit_train <- Arima(df_train, order = c(0, 0, 0), seasonal = c(2, 1, 2)))
summary(m1) 
BIC(m1)
forecast.m1 <- forecast(m1, h=24)
accuracy(forecast(m1, h=24), df_test)
```

```{r, echo=FALSE, results='hide'}
acf2(resid(m1), max.lag=60) 
```

```{r, echo=FALSE}
checkresiduals(m1, test="LB") 
jarque.bera.test(residuals(m1))
```
\
ANÁLISE:\

Quase todas as autocorrelações dos resíduos estão dentro dos limites - indicando que os resíduos se comportam como um ruído branco.\

P-valor do teste Ljung-Box é maior que o nível de significância de 5% (0.05). Pode-se concluir pela não rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos). Portanto, segundo o teste Ljung-Box, não se rejeita a hipótese que os resíduos se comportam como um ruído branco.\

P-valor do teste Jarque-Bera é maior que o nível de significância de 5% (0.05). Pode-se concluir pela não rejeição da hipótese nula (que os resíduos são normalmente distribuídos). Portanto, segundo o teste Jarque-Bera, não se rejeita a hipótese que os resíduos se comportam como um ruído branco.

### d) Modelo 2 = ETS (suavização exponencial com tendência e sazonalidade)\

```{r, echo=FALSE}
m2 <- ets(df_train)
summary(m2) 
BIC(m2) #BIC=6211.15
forecast.m2 <- forecast(m2, h=24)
accuracy(forecast(m2, h=24), df_test)
```

```{r, echo=FALSE, results='hide'}
acf2(resid(m2), max.lag=60)
```

```{r, echo=FALSE}
checkresiduals(m2, test="LB")
```
\
ANÁLISE:\

As autocorrelações dos resíduos mostram decaimento exponencial sazonal - indicando que os resíduos não se comportam como um ruído branco.\

P-valor do teste Ljung-Box é menor que o nível de significância de 5% (0.05). Pode-se concluir pela rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos). Portanto, segundo o teste Ljung-Box, rejeita-se a hipótese que os resíduos se comportam como um ruído branco.

### e) Modelo 3 = TSLM (linear com tendência e sazonalidade)\

```{r, echo=FALSE}
m3 <- tslm(df_train ~ season + trend) 
summary(m3) 
BIC(m3) #BIC=5445.32
forecast.m3 <- forecast(m3, h=24)
accuracy(forecast(m3, h=24), df_test)
```

```{r, echo=FALSE, results='hide'}
acf2(resid(m3), max.lag=60)
```

```{r, echo=FALSE}
checkresiduals(m3, test="LB")
```
\
ANÁLISE:\

As autocorrelações dos resíduos mostram decaimento exponencial sazonal - indicando que os resíduos não se comportam como um ruído branco.\

P-valor do teste Ljung-Box é menor que o nível de significância de 5% (0.05). Pode-se concluir pela rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos). Portanto, segundo o teste Ljung-Box, rejeita-se a hipótese que os resíduos se comportam como um ruído branco.

### f) Modelo 4 = Holt-Winters (suavização exponencial tripla)\

```{r, echo=FALSE}
m4 <- holt(df_train, h = 24)
summary(m4)
forecast.m4 <- forecast(m4, h=24)
accuracy(forecast(m4, h=24), df_test)
```

```{r, echo=FALSE, results='hide'}
acf2(resid(m4), max.lag=60)
```

```{r, echo=FALSE}
checkresiduals(m4, test="LB")
```
\
ANÁLISE:\

As autocorrelações dos resíduos mostram decaimento exponencial sazonal - indicando que os resíduos não se comportam como um ruído branco.\

P-valor do teste Ljung-Box é menor que o nível de significância de 5% (0.05). Pode-se concluir pela rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos). Portanto, segundo o teste Ljung-Box, rejeita-se a hipótese que os resíduos se comportam como um ruído branco.

### g) Modelo 5 = Holt-Winters + damped (suavização exponencial tripla - amortecida)\

```{r, echo=FALSE}
m5 <- holt(df_train, damped = TRUE, h = 24)
summary(m5) 
forecast.m5 <- forecast(m5, h=24)
accuracy(forecast(m5, h=24), df_test)
```

```{r, echo=FALSE, results='hide'}
acf2(resid(m5), max.lag=60) 
```

```{r, echo=FALSE}
checkresiduals(m5, test="LB")
```
\
ANÁLISE:\

As autocorrelações dos resíduos mostram decaimento exponencial sazonal - indicando que os resíduos não se comportam como um ruído branco.\

P-valor do teste Ljung-Box é menor que o nível de significância de 5% (0.05).Pode-se concluir pela rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos).Portanto, segundo o teste Ljung-Box, rejeita-se a hipótese que os resíduos se comportam como um ruído branco.

### h) Modelo 6 = SES (suavização exponencial simples)

```{r, echo=FALSE}
m6 <- ses(df_train, h = 24)
summary(m6)
forecast.m6 <- forecast(m6, h=24)
accuracy(forecast(m6, h=24), df_test)
```

```{r, echo=FALSE, results='hide'}
acf2(resid(m6), max.lag=60) 
```

```{r, echo=FALSE}
checkresiduals(m6, test="LB")
```
\
ANÁLISE:\

As autocorrelações dos resíduos mostram decaimento exponencial sazonal - indicando que os resíduos não se comportam como um ruído branco.\

P-valor do teste Ljung-Box é menor que o nível de significância de 5% (0.05). Pode-se concluir pela rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos). Portanto, segundo o teste Ljung-Box, rejeita-se a hipótese que os resíduos se comportam como um ruído branco.

### i) Modelo 7 = NAIVE (modelo "ingênuo" / passeio aleatório com tendência)

```{r, echo=FALSE}
m7 <- naive(df_train, h = 24)
summary(m7) 
forecast.m7 <- forecast(m7, h=24)
accuracy(forecast(m7, h=24), df_test)
```

```{r, echo=FALSE, results='hide'}
acf2(resid(m7), max.lag=60)
```

```{r, echo=FALSE}
checkresiduals(m7, test="LB")
```
\
ANÁLISE:\

As autocorrelações dos resíduos mostram decaimento exponencial sazonal - indicando que os resíduos não se comportam como um ruído branco.\

P-valor do teste Ljung-Box é menor que o nível de significância de 5% (0.05). Pode-se concluir pela rejeição da hipótese nula (que os resíduos são indepedentementes distribuídos). Portanto, segundo o teste Ljung-Box, rejeita-se a hipótese que os resíduos se comportam como um ruído branco.

### j) Resultado da avaliação do melhor modelo de previsão\

SARIMA(0,0,0)(2,1,2)12 teve melhor performance / menor BIC, RMSE, MAPE e Theil's U.\

ETS teve a segunda melhor performance / terceiro menor BIC e segundo menor RMSE, MAPE e Theil's U. Registre-se que essa modelagem não passou no teste Ljung-Box de distribuição independente dos resíduos.\

TSLM teve a terceira melhor performance / segundo menor BIC e terceiro menor RMSE, MAPE e Theil's U. Registre-se que essa modelagem não passou no teste Ljung-Box de distribuição independente dos resíduos.

## 8) Previsão\

### a) SARIMA(0,0,0)(2,1,2)12 - modelo com melhor perfomance

```{r, echo=FALSE, results='hide'}
autoplot(forecast(m1, h = 24), include = 500) +
  autolayer(df_test)
autoplot(forecast(m1, h = 24), include = 50) +
  autolayer(df_test)
```

### b) ETS - modelo com segunda melhor perfomance

```{r, echo=FALSE, results='hide'}
autoplot(forecast(m2, h = 24), include = 500) +
  autolayer(df_test) 
autoplot(forecast(m2, h = 24), include = 50) +
  autolayer(df_test)
```

### c) TSLM - modelo com terceira melhor perfomance

```{r, echo=FALSE, results='hide'}
autoplot(forecast(m3, h = 24), include = 500) +
  autolayer(df_test) 
autoplot(forecast(m3, h = 24), include = 50) +
  autolayer(df_test)
```

## 9) Random Forest\

```{r, echo=FALSE, results='hide'}
dfrf <- df %>% timetk::tk_augment_lags(x, .lags = 1:12)
dfrf2 <- dfrf[-c(1:12),]
rfts <- ts(dfrf2$x, frequency = 12)
xreg_rfts <- ts(dfrf2$x_lag12, frequency = 12)
rf_split <- ts_split(rfts, sample.out = 24)
rf_train <- rf_split$train
rf_test <- rf_split$test
xregrf_split <- ts_split(xreg_rfts, sample.out = 24)
xregrf_train <- xregrf_split$train
xregrf_test <- xregrf_split$test
```

```{r, echo=FALSE}
Random_Forest <- randomForest(rf_train ~ ., data = xregrf_train, 
                                importance = TRUE)
print(Random_Forest)
pred.rf <- predict(Random_Forest, newdata = xregrf_test, n.ahead = 24)
accuracy(pred.rf,rf_test)
```
\
ANÁLISE:\

Random Forest obteve menor RMSE, MAPE e Theil's U que os demais modelos - exceto o SARIMA(0,0,0)(2,1,2)12 e o ETS.\

Portanto, pode-se considerar que Random Forest atingiu a terceira melhor perfomance entre as modelagens aqui consideradas.

## 10) Apêndice (código R)\

rm(list=ls())\

graphics.off()\

library(urca)\

library(forecast)\

library(astsa)\

library(tseries)\

library(TSstudio)\

library(randomForest)\

df <- read.csv("C:/Users/mvrgu/OneDrive/Documentos/Scanned Documents/Mestrado/Estatística Econômica Aplicada/data_MarcusGuerra.csv", header = T,sep = ",", dec = ".")\

plot(df[,1], df[,2], type = "l", col = "black", lty=1, main="Série Original", xlab="Observações", ylab="Valores", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

acf2(df[,2], max.lag=60, main="Correlogramas da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

df1 <- ts(df, frequency=12)\

dfcomponents1 <- stl(df1[,2], t.window=13, s.window="periodic", robust=TRUE)\

plot(dfcomponents1, main="Decomposição da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

df.first_diff <- diff(df[,2])\

plot(df.first_diff, type = "l", col = "black", lty=1, main="Primeira Diferença da Série Original", xlab="Observações", ylab="Valores", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

acf2(df.first_diff, max.lag=60, main="Correlogramas da Primeira Diferença da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

df1.first_diff <- diff(df1[,2])\

dfcomponents2 <- stl(df1.first_diff, t.window=13, s.window="periodic", robust=TRUE)\

plot(dfcomponents2, main="Decomposição da Primeira Diferença da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

df.first_sdiff12 <- diff(df[,2],12)\

plot(df.first_sdiff12, type = "l", col = "black", lty=1, main="Primeira Diferença Sazonal de Ordem 12 da Série Original", xlab="Observações", ylab="Valores", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

acf2(df.first_sdiff12, max.lag=60, main="Correlogramas da Primeira Diferença Sazonal de Ordem 12 da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

df1.first_sdiff12 <- diff(df1[,2],12)\

dfcomponents3 <- stl(df1.first_sdiff12, t.window=13, s.window="periodic", robust=TRUE)\

plot(dfcomponents3, main="Decomposição da Primeira Diferença Sazonal de Ordem 12 da Série Original", cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

test.adf <- ur.df(df1.first_sdiff12, lags = 60, type = "drift", selectlags = "BIC")\

summary(test.adf)\

test.kpss <- ur.kpss(df1.first_sdiff12, type = "mu", use.lag=NULL)\

summary(test.kpss)\

kpss.test(df1.first_sdiff12)\

(fit1 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(4, 1, 4)))\

(fit2 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(4, 1, 3)))\

(fit3 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(4, 1, 2)))\

(fit4 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(4, 1, 1)))\

(fit5 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(4, 1, 0)))\

(fit6 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(3, 1, 4)))\

(fit7 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(3, 1, 3)))\

(fit8 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(3, 1, 2)))\

(fit9 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(3, 1, 1)))\

(fit10 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(3, 1, 0)))\

(fit11 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(2, 1, 4)))\

(fit12 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(2, 1, 3)))\

(fit13 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(2, 1, 2)))\

(fit14 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(2, 1, 1)))\

(fit15 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(2, 1, 0)))\

(fit16 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(1, 1, 4)))\

(fit17 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(1, 1, 3)))\

(fit18 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(1, 1, 2)))\

(fit19 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(1, 1, 1)))\

(fit20 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(1, 1, 0)))\

(fit21 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(0, 1, 4)))\

(fit22 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(0, 1, 3)))\

(fit23 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(0, 1, 2)))\

(fit24 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(0, 1, 1)))\

(fit25 <- Arima(df1[,2], order = c(0, 0, 0), seasonal = c(0, 1, 0)))\

fit26 <- auto.arima(df1[,2], p=0, d=0, max.q=0, max.P=4, D=1, max.Q=4, stepwise = FALSE, max.order = 8, approximation = FALSE, test = "adf", ic = "bic", trace = TRUE)\

summary(fit26)\

autoplot(fit13)\

acf2(resid(fit13), max.lag=60,  cex.main=1, cex.lab=1, font.main=1, font.lab=1)\

checkresiduals(fit13, test="LB")\

jarque.bera.test(residuals(fit13))\

df_split <- ts_split(df1[,2], sample.out = 24)\

df_train <- df_split$train\

df_test <- df_split$test\

m1 <- (fit_train <- Arima(df_train, order = c(0, 0, 0), seasonal = c(2, 1, 2)))\

summary(m1)\

BIC(m1)\

forecast.m1 <- forecast(m1, h=24)\

accuracy(forecast(m1, h=24), df_test)\

checkresiduals(m1, test="LB")\

acf2(resid(m1), max.lag=60)\

jarque.bera.test(residuals(m1))\

m2 <- ets(df_train)\

summary(m2)\

BIC(m2)\

forecast.m2 <- forecast(m2, h=24)\

accuracy(forecast(m2, h=24), df_test)\

checkresiduals(m2, test="LB")\

acf2(resid(m2), max.lag=60)\

m3 <- tslm(df_train ~ season + trend)\

summary(m3)\

BIC(m3)\

forecast.m3 <- forecast(m3, h=24)\

accuracy(forecast(m3, h=24), df_test)\

checkresiduals(m3, test="LB")\

acf2(resid(m3), max.lag=60)\

m4 <- holt(df_train, h = 24)\

summary(m4)\

forecast.m4 <- forecast(m4, h=24)\

accuracy(forecast(m4, h=24), df_test)\

checkresiduals(m4, test="LB")\

acf2(resid(m4), max.lag=60)\

m5 <- holt(df_train, damped = TRUE, h = 24)\

summary(m5)\

forecast.m5 <- forecast(m5, h=24)\

accuracy(forecast(m5, h=24), df_test)\

checkresiduals(m5, test="LB")\

acf2(resid(m5), max.lag=60)\

m6 <- ses(df_train, h = 24)\

summary(m6)\

forecast.m6 <- forecast(m6, h=24)\

accuracy(forecast(m6, h=24), df_test)\

checkresiduals(m6, test="LB")\

acf2(resid(m6), max.lag=60)\

m7 <- naive(df_train, h = 24)\

summary(m7)\

forecast.m7 <- forecast(m7, h=24)\

accuracy(forecast(m7, h=24), df_test)\

checkresiduals(m7, test="LB")\

acf2(resid(m7), max.lag=60)\

autoplot(forecast(m1, h = 24), include = 500) + autolayer(df_test)\

autoplot(forecast(m1, h = 24), include = 50) + autolayer(df_test)\

autoplot(forecast(m2, h = 24), include = 500) + autolayer(df_test)\

autoplot(forecast(m2, h = 24), include = 50) + autolayer(df_test)\

autoplot(forecast(m3, h = 24), include = 500) + autolayer(df_test)\

autoplot(forecast(m3, h = 24), include = 50) + autolayer(df_test)\

dfrf <- df %>% timetk::tk_augment_lags(x, .lags = 1:12)\

dfrf2 <- dfrf[-c(1:12),]\

rfts <- ts(dfrf2$x, frequency = 12)\

xreg_rfts <- ts(dfrf2$x_lag12, frequency = 12)\

rf_split <- ts_split(rfts, sample.out = 24)\

rf_train <- rf_split$train\

rf_test <- rf_split$test\

xregrf_split <- ts_split(xreg_rfts, sample.out = 24)\

xregrf_train <- xregrf_split$train\

xregrf_test <- xregrf_split$test\

Random_Forest <- randomForest(rf_train ~ ., data = xregrf_train, importance = TRUE)\

print(Random_Forest)\

pred.rf <- predict(Random_Forest, newdata = xregrf_test, n.ahead = 24)\

accuracy(pred.rf,rf_test)